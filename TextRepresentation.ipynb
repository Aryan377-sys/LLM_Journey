{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot-Encoding\n",
    "### Problems with one-hot encoding is:\n",
    "\n",
    "#### Increased Dimensionality and Sparsity:\n",
    "\n",
    "#### One-hot encoding significantly increases the number of features in your data, leading to:\n",
    "\n",
    "- **Slower training: Machine learning models take longer to train with more features.**\n",
    "- **Overfitting: Models become overly complex and might not generalize well to unseen data.**\n",
    "- **Sparse data: Most entries in one-hot encoded features are zeros, potentially impacting certain algorithms reliant on dense data or distance calculations.**\n",
    "\n",
    "### Other options apart from OHE are:-\n",
    "- *Label Encoding*\n",
    "- *Frequency Encoding*\n",
    "- *Target Encoding*\n",
    "- *Embedding Techniques*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer\n",
    "\n",
    "- **class sklearn.feature_extraction.text.CountVectorizer**\n",
    " **(*, input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, stop_words=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), analyzer='word', max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.int64'>)**\n",
    "\n",
    "- #### Using bi/tri/quad-grams increases dimensionality which ultimately increases the time complexity of the problem.\n",
    "\n",
    "- #### Here try using ngram_range=(1,2)/(1,3) for better result but increase in little time complexity see fro yourself what happens when use them on a dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "text=pd.DataFrame({\"Text\":[\"Sohan is a good boy\",\"Sohan plays badminton\",\"Sohan studies Maths\"],\"Outputs\":[1,0,0]})\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing CountVectorizer\n",
    "### **from sklearn.feature_extraction.text import CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(ngram_range=(1,2))\n",
    "bag_of_words=cv.fit_transform(text['Text'])\n",
    "print(cv.vocabulary_)\n",
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf\n",
    "\n",
    "- ### Doesn't solve the problem of semantic relationship\n",
    "- #### Other problems that remains are:-\n",
    "  - **Sparsity**\n",
    "  - **OOV**\n",
    "  - **Big Dimensionality like before one**\n",
    "\n",
    "\n",
    "### Interview Questions:-\n",
    "  - #### Why log is used in idf formula?\n",
    "  - #### why the models use the formula log(N/n)+1,where\n",
    "       - **N= No. of Documents**\n",
    "       - **n= No. of documents with 't' term in it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['about', 'accustomed', 'after', 'agenda', 'agreements', 'all',\n",
       "       'an', 'and', 'appeal', 'are', 'around', 'aryans', 'as',\n",
       "       'audiences', 'away', 'be', 'become', 'being', 'bitches', 'br',\n",
       "       'brutality', 'but', 'called', 'can', 'cells', 'charm',\n",
       "       'christians', 'city', 'class', 'classic', 'comfortable', 'couldn',\n",
       "       'crooked', 'dare', 'darker', 'dealings', 'death', 'developed',\n",
       "       'dodgy', 'doesn', 'drugs', 'due', 'em', 'emerald', 'episode',\n",
       "       'ever', 'exactly', 'experience', 'experimental', 'face', 'fact',\n",
       "       'faint', 'far', 'first', 'focuses', 'for', 'forget', 'from',\n",
       "       'fronts', 'gangstas', 'get', 'given', 'glass', 'go', 'goes', 'got',\n",
       "       'graphic', 'guards', 'happened', 'hardcore', 'has', 'have',\n",
       "       'hearted', 'high', 'home', 'hooked', 'if', 'in', 'injustice',\n",
       "       'inmates', 'into', 'inwards', 'irish', 'is', 'it', 'italians',\n",
       "       'its', 'just', 'kill', 'lack', 'latinos', 'levels', 'll', 'main',\n",
       "       'mainly', 'mainstream', 'mannered', 'many', 'maximum', 'may', 'me',\n",
       "       'mentioned', 'mess', 'middle', 'more', 'muslims', 'nasty', 'never',\n",
       "       'nickel', 'nickname', 'no', 'not', 'of', 'on', 'one', 'or',\n",
       "       'order', 'oswald', 'other', 'out', 'oz', 'painted', 'penitentary',\n",
       "       'pictures', 'pretty', 'prison', 'privacy', 'pulls', 'punches',\n",
       "       'ready', 'regards', 'reviewers', 'right', 'romance', 'saw', 'say',\n",
       "       'scenes', 'scuffles', 'section', 'security', 'set', 'sex', 'shady',\n",
       "       'show', 'shows', 'side', 'skills', 'so', 'sold', 'stares', 'state',\n",
       "       'street', 'struck', 'surreal', 'taste', 'that', 'thats', 'the',\n",
       "       'their', 'they', 'thing', 'this', 'timid', 'to', 'touch', 'trust',\n",
       "       'turned', 'uncomfortable', 'unflinching', 'use', 'viewing',\n",
       "       'violence', 'was', 'watched', 'watching', 'well', 'what', 'where',\n",
       "       'which', 'who', 'with', 'word', 'would', 'wouldn', 'you', 'your'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "tfidf=TfidfVectorizer()\n",
    "data=pd.read_csv(\"/home/sohanx1/Downloads/Sohan/sohan/PYTHON WORKS/llm/LLM CampusX/IMDB Review Dataset .csv\")\n",
    "Reviews=pd.DataFrame({'review':data['review'][:1]}) # # Making a new dataset with only 4 documents from column review from my original dataset\n",
    "#Reviews['review']=data['review'][:1] \n",
    "tfidf.fit_transform(Reviews['review']).toarray()\n",
    "tfidf.get_feature_names_out()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sohanpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
